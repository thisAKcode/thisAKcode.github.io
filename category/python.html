<!DOCTYPE html>
<html lang="en">
<head>
        <meta charset="utf-8" />
        <meta name="generator" content="Pelican" />
        <title>PrettyLagom - python</title>
        <link rel="stylesheet" href="/theme/css/main.css" />
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="/">PrettyLagom</a></h1>
                <nav><ul>
                    <li><a href="/pages/about.html">About</a></li>
                    <li><a href="/category/art.html">art</a></li>
                    <li><a href="/category/misc.html">misc</a></li>
                    <li class="active"><a href="/category/python.html">python</a></li>
                    <li><a href="/category/sql.html">sql</a></li>
                    <li><a href="/category/stats.html">stats</a></li>
                    <li><a href="/p5serve/index.html">p5.js Sketches</a></li>
                </ul></nav>
        </header><!-- /#banner -->

            <aside id="featured" class="body">
                <article>
                    <h1 class="entry-title"><a href="/some-dl.html">Some DL.</a></h1>
<footer class="post-info">
        <abbr class="published" title="2024-10-21T00:00:00+02:00">
                Published: Mon 21 October 2024
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info --><style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
 .highlight pre  .hll { background-color: #ffffcc }
 .highlight pre  { background: #f8f8f8; }
 .highlight pre  .c { color: #408080; font-style: italic } /* Comment */
 .highlight pre  .err { border: 1px solid #FF0000 } /* Error */
 .highlight pre  .k { color: #008000; font-weight: bold } /* Keyword */
 .highlight pre  .o { color: #666666 } /* Operator */
 .highlight pre  .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
 .highlight pre  .cm { color: #408080; font-style: italic } /* Comment.Multiline */
 .highlight pre  .cp { color: #BC7A00 } /* Comment.Preproc */
 .highlight pre  .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
 .highlight pre  .c1 { color: #408080; font-style: italic } /* Comment.Single */
 .highlight pre  .cs { color: #408080; font-style: italic } /* Comment.Special */
 .highlight pre  .gd { color: #A00000 } /* Generic.Deleted */
 .highlight pre  .ge { font-style: italic } /* Generic.Emph */
 .highlight pre  .gr { color: #FF0000 } /* Generic.Error */
 .highlight pre  .gh { color: #000080; font-weight: bold } /* Generic.Heading */
 .highlight pre  .gi { color: #00A000 } /* Generic.Inserted */
 .highlight pre  .go { color: #888888 } /* Generic.Output */
 .highlight pre  .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
 .highlight pre  .gs { font-weight: bold } /* Generic.Strong */
 .highlight pre  .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
 .highlight pre  .gt { color: #0044DD } /* Generic.Traceback */
 .highlight pre  .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
 .highlight pre  .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
 .highlight pre  .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
 .highlight pre  .kp { color: #008000 } /* Keyword.Pseudo */
 .highlight pre  .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
 .highlight pre  .kt { color: #B00040 } /* Keyword.Type */
 .highlight pre  .m { color: #666666 } /* Literal.Number */
 .highlight pre  .s { color: #BA2121 } /* Literal.String */
 .highlight pre  .na { color: #7D9029 } /* Name.Attribute */
 .highlight pre  .nb { color: #008000 } /* Name.Builtin */
 .highlight pre  .nc { color: #0000FF; font-weight: bold } /* Name.Class */
 .highlight pre  .no { color: #880000 } /* Name.Constant */
 .highlight pre  .nd { color: #AA22FF } /* Name.Decorator */
 .highlight pre  .ni { color: #999999; font-weight: bold } /* Name.Entity */
 .highlight pre  .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
 .highlight pre  .nf { color: #0000FF } /* Name.Function */
 .highlight pre  .nl { color: #A0A000 } /* Name.Label */
 .highlight pre  .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
 .highlight pre  .nt { color: #008000; font-weight: bold } /* Name.Tag */
 .highlight pre  .nv { color: #19177C } /* Name.Variable */
 .highlight pre  .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
 .highlight pre  .w { color: #bbbbbb } /* Text.Whitespace */
 .highlight pre  .mb { color: #666666 } /* Literal.Number.Bin */
 .highlight pre  .mf { color: #666666 } /* Literal.Number.Float */
 .highlight pre  .mh { color: #666666 } /* Literal.Number.Hex */
 .highlight pre  .mi { color: #666666 } /* Literal.Number.Integer */
 .highlight pre  .mo { color: #666666 } /* Literal.Number.Oct */
 .highlight pre  .sa { color: #BA2121 } /* Literal.String.Affix */
 .highlight pre  .sb { color: #BA2121 } /* Literal.String.Backtick */
 .highlight pre  .sc { color: #BA2121 } /* Literal.String.Char */
 .highlight pre  .dl { color: #BA2121 } /* Literal.String.Delimiter */
 .highlight pre  .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
 .highlight pre  .s2 { color: #BA2121 } /* Literal.String.Double */
 .highlight pre  .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
 .highlight pre  .sh { color: #BA2121 } /* Literal.String.Heredoc */
 .highlight pre  .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
 .highlight pre  .sx { color: #008000 } /* Literal.String.Other */
 .highlight pre  .sr { color: #BB6688 } /* Literal.String.Regex */
 .highlight pre  .s1 { color: #BA2121 } /* Literal.String.Single */
 .highlight pre  .ss { color: #19177C } /* Literal.String.Symbol */
 .highlight pre  .bp { color: #008000 } /* Name.Builtin.Pseudo */
 .highlight pre  .fm { color: #0000FF } /* Name.Function.Magic */
 .highlight pre  .vc { color: #19177C } /* Name.Variable.Class */
 .highlight pre  .vg { color: #19177C } /* Name.Variable.Global */
 .highlight pre  .vi { color: #19177C } /* Name.Variable.Instance */
 .highlight pre  .vm { color: #19177C } /* Name.Variable.Magic */
 .highlight pre  .il { color: #666666 } /* Literal.Number.Integer.Long */</style><body><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Deep-Learning-Tools">Deep Learning Tools<a class="anchor-link" href="#Deep-Learning-Tools">&#182;</a></h3><h3 id="Machine-Learning">Machine Learning<a class="anchor-link" href="#Machine-Learning">&#182;</a></h3><p>Difference/similarities between DL and ML.
In ML model receives data and get patterns and make a representation that fits best the data. Then when you input the new data model figures out a class or label for each datapoint. So <strong>learning</strong> is the storing collections of patterns that are used to make assumption about new input. DL is a subtype of ML.</p>
<h3 id="Deep">Deep<a class="anchor-link" href="#Deep">&#182;</a></h3><p>The deep is because you have deep structure of layers that put on top of each other and it is similar to the structure of the brain where numerous layers of neural networks perform steps to identify patterns and categorize stuff around us. Deep stack of abstract layers are interconnected in a special way based on a data feed into it.</p>
<p>Deep learning is different from the ML since you not always need to make feature extraction for a model (always necessary in ML): a representational learning can learn from raw input.</p>
<p>Another difference between DL and ML is that large amounts of data is the crucial parameter for  DL, without massive amount of training data it is less accurate than less complex ML models.</p>
<p>DL application need to process thousand sometimes millions of objects to start react is a appropriate way when such an object appears in a system.</p>
<h3 id="Simultaneous-Multiple-Computations-Along-Neural-Networks">Simultaneous Multiple Computations Along Neural Networks<a class="anchor-link" href="#Simultaneous-Multiple-Computations-Along-Neural-Networks">&#182;</a></h3><p>To recognize objects in the way human does was something that computers found difficult until Rosenblatts perceptron algorithm 1953 was developed. It was able to solve image recognition problem. Later Multilayer Perceptron (Feedforward Network) was derived from it - sequentially processed input through multiple layers of neurons each time making decisions returning meaningful output.</p>
<h3 id="GPU">GPU<a class="anchor-link" href="#GPU">&#182;</a></h3><p>Processing power of high-performance graphics processing units is a driving parameter that makes DL executed fast compared to execution on CPU. GPUs are essential for deep learning (DL) because they can quickly perform parallel processing of matrices, vectors, and scalars.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Common-Deep-Learning-Concepts">Common Deep Learning Concepts<a class="anchor-link" href="#Common-Deep-Learning-Concepts">&#182;</a></h3><h3 id="Types-of-Deep-Learning">Types of Deep Learning<a class="anchor-link" href="#Types-of-Deep-Learning">&#182;</a></h3><table>
<thead><tr>
<th>Type</th>
<th>Input Data</th>
<th>Principle</th>
<th>Year of Breakthrough</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Reinforcement Learning</strong></td>
<td>Various</td>
<td>Trains agents to make sequential decisions by interacting with an environment to maximize cumulative rewards.</td>
<td>1950s</td>
</tr>
<tr>
<td><strong>Recurrent Neural Networks (RNNs)</strong></td>
<td>Sequential data (e.g., text)</td>
<td>Use recurrent layers to maintain state across inputs and time steps.</td>
<td>1986</td>
</tr>
<tr>
<td><strong>Convolutional Neural Networks (CNNs)</strong></td>
<td>Grid-like data (e.g., images)</td>
<td>Use convolutional layers to extract features, pooling layers to reduce feature map size, and fully connected layers for classification.</td>
<td>1989</td>
</tr>
<tr>
<td><strong>Autoencoders</strong></td>
<td>Various</td>
<td>Learn data representations by compressing and decompressing input data.</td>
<td>2006</td>
</tr>
<tr>
<td><strong>Transfer Learning</strong></td>
<td>Various</td>
<td>Uses pre-trained models to solve new tasks by freezing some layers and retraining others.</td>
<td>2014</td>
</tr>
</tbody>
</table>
<h3 id="Maths.-Linear-Algebra.">Maths. Linear Algebra.<a class="anchor-link" href="#Maths.-Linear-Algebra.">&#182;</a></h3><p>Understanding linear algebra is crucial for DL.</p>
<p><a href="https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&amp;a_bid=76564dff">Chollet's book</a> quickly covers the most relevant datastructures and datatypes for tensorflow(btw tensors are n-d arrays), here shown as python (numpy) objects.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1"># scalar</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">1</span>
<span class="c1"># matrices</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>

<span class="c1"># vectors</span>
<span class="n">y</span>  <span class="o">=</span> <span class="n">z</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># [1,2,3]</span>

<span class="n">tensor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span> <span class="c1"># see below</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Level 1:</span>
<span class="sd">[[0. 0. 0. 0. 0.]</span>
<span class="sd"> [0. 0. 0. 0. 0.]]</span>

<span class="sd">Level 2:</span>
<span class="sd">[[0. 0. 0. 0. 0.]</span>
<span class="sd"> [0. 0. 0. 0. 0.]]</span>

<span class="sd">Level 3:</span>
<span class="sd">[[0. 0. 0. 0. 0.]</span>
<span class="sd"> [0. 0. 0. 0. 0.]]</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
<ul>
<li>The tensor <code>tensor</code> is a 3D array with shape <code>[3, 2, 5]</code>.</li>
<li>This means it has 3 levels, each containing a list of lists (2x5 matrix).</li>
<li>The first level is list of lists of 2x5 matrices.</li>
</ul>
<p>Jake VanderPlas covers the <a href="https://jakevdp.github.io/PythonDataScienceHandbook/02.02-the-basics-of-numpy-arrays.html#Multi-dimensional-subarrays:~:text=Multi%2Ddimensional%20subarrays,Multi%2Ddimensional%20slices">dimensionality</a> of nested numpy arrays (shapes) and matrix algebra (I assembled it in another article here: &lt;&gt;).</p>
<h3 id="Scalars/Matrix-Addition-&amp;-Multiplication">Scalars/Matrix Addition &amp; Multiplication<a class="anchor-link" href="#Scalars/Matrix-Addition-&amp;-Multiplication">&#182;</a></h3><div class="highlight"><pre><span></span><span class="c1"># scalars/matrix addition &amp; multiplication</span>
<span class="c1"># Given:</span>
    <span class="n">matrix_a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
    <span class="n">matrix_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span> <span class="p">[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>  <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">12</span><span class="p">]])</span>
<span class="c1"># multiplication</span>
    <span class="n">matrix_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix_a</span><span class="p">,</span> <span class="n">matrix_b</span><span class="p">)</span> <span class="c1"># [[58, 64], [139, 154]]</span>
    <span class="c1"># wich in native python would be:</span>

    <span class="n">matrix_c2</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>

    <span class="c1"># for each row in first matrix</span>
    <span class="c1"># for each element k in row i of A and corresponding element k in column j of B</span>
    <span class="c1"># (k ranges from 0 to len of first matrix):</span>
    <span class="c1">#    Multiply A[i][k] by B[k][j]</span>
    <span class="c1">#    Add the result to sum: set C[i][j] = sum</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">matrix_a</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">matrix_b</span><span class="p">:</span>
            <span class="n">matrix_c2</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span>
                <span class="n">matrix_a</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">matrix_b</span><span class="p">[</span><span class="n">k</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">matrix_a</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
            <span class="p">)</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    Matrix A (2x3) and Matrix B (3x2)</span>
<span class="sd">    Result matrix C will have shape (2x2) and vice versa B x A will have shape (3x3)</span>
<span class="sd">    &#39;&#39;&#39;</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="n">Image</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;C:\thisAKcode.github.io\Pelican\content\images\matrix_mult.png&#39;</span><span class="p">,</span>  <span class="n">width</span> <span class="o">=</span> <span class="mi">600</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>




<div class="output_png output_subarea output_execute_result">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAjYAAAEgCAYAAACn0TkuAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAEnQAABJ0Ad5mH3gAADmbSURBVHhe7d0FlOzUAYdx3N3d3d1b3N2d4hQv7lqglOJWXAuUosVb3LW4u7u7357vvg3MmzeyeyfZmQnf75yc997u5GaTzUv+uZbBgiRJUkkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJUmkYbCRJqnDCCSeEAw88MLzwwgvhp59+6vlqd3v++efD3nvvHa688srwzTff9Hy1nAw2kqRSIpRwE//yyy/D999/H37++eee7wyK7//444/x74svvniYYYYZwl133RV++OGH8N133zUMOJTL57JtsXz99ddxvUbb7AvK4Wes3AZ/z37mWvhett+33nprmHjiicO+++4bPvvss/g9fuZ6P1/1/nz11Ve57k+RDDaSpNL58MMPw1VXXRXWXXfdMOuss4Zzzz033qBr+fjjj8Nf//rXcNFFF4V33303bLzxxmGeeeYJd999d7j99tvDLrvsEm677bZ4Y6/Gzf+BBx4If/vb38LKK68c5phjjjDzzDOHJZZYItaQPPfccz2fTMfPfeedd4aDDjoorLTSSmG22WYLs88+e1hllVVi7dLLL788SMAh0FxzzTXhsMMOiz8fPz/H4cgjjwyvvPJKOPvss8NJJ50U3nnnnZ41BqCcJ598Mhx11FFh1VVXjdthfxZeeOGw0047hf/+97/h888/7+iAY7CRJJUGQYNAsuuuu8Zal+GHHz4MPvjg4fDDD481FbU88cQTYfnll4+f33nnncNqq60WQwDBZIEFFgjTTDNNOOOMM8IXX3zRs8YA1GJccMEFYcEFFwyTTDJJmH/++WPwWH311WOtz1xzzRUuv/zynk+nu/TSS8N8880XJpxwwhic2N7UU08dRhpppDDmmGOGjTbaKDY1VdYqsa9HH310/Nl///vfx3A244wzhh133DFsv/32Ydpppw3rrbdeeOaZZ3rWGODee++Nx4LanbnnnjuGNQIOYWrssceOIYcAyL53qo4NNrZxSpL6guvqmWeeGWtbxh9//LDccsvFsEKw+ctf/lI32BBYqJmhRoTQMO6444YRRxwx3sT/+Mc/hksuuSS8/vrrA9WK8Pdrr7023vBHHXXUsPvuu4c77rgj3rOoEXnkkUfC9ddfH2tTWrXffvuFtddeO94XqXl56KGHYm3MmmuuGYPbKKOMEk4++eSBaqRoSnrppZfChRdeGDbddNMYZAhC7Bu1SdTk3HPPPQOFNWpittpqq/g5ws0NN9wQ94d9oKZmjTXWCCOMMEJYdNFFw6uvvtqzVucpPNgU2cZZWXa9pdvaOPk3SbhyH+otzY6nJP2W0PzEjXnZZZeNtQoPPvhgrD1pFmy4l3BTv+mmm8JSSy0Vhh122DDEEEOE6aef/pfmGq7Nld57770YeggBXNPffvvtPj+E0w+HZh+Wb7/9tuergyJUsVR+hvsHwWTeeecNQw45ZNhggw3iz5TJ7lf8XNTcTDbZZPFzLAQU7kfsc+XP/NRTT8XanZFHHjmcddZZA9XKsD1C0qSTThpDY3VNTycpNNgU3cZJYtxiiy1i2TPNNNMgyyyzzBJP5jyqzPi5W23jZD+atXHy+cUWW6zm/lQuc845Z9wuJ6YkacCD4bPPPhuvxzx0ci9ZZ511mgYbajZ22GGHeE3noZpmH27g1PhwzSYocW2mzAyhgqYdrsXUzvQ11IBAQ8jgXpXSF+eNN96INSvsHz8jISbDPeuf//xn3B/Kp5aGfSK4cY/h595nn33Ca6+91rPGgCa5hRZa6JdgQ/DKEJRoEpt88snDlFNOGVsgOlUhwYZffn+0cXICUyU2zjjjxLZMqhArF5InN//KX06q/mrjvO6668KKK644yL5kC//xqHbkmBKyPv300541JUlcg7Oa7N4GmxdffDF+jgflW265JWy22Wbxev/vf/87HHroofFmf/755//ykMw2TjnllNjnhFobHuJTPPzww/G6zn2Ee2Bf8YC8zDLLxFoYKgPef//9nu8MCDYnnnhiWHrppWPHZprTuHfxd5qY+PzWW289UEDhfsLXaW6ipoufLzuehKhtt902NtGxXuW2Ok3uwYZQ019tnASCRRZZJCZR2jr/97//DbSQolOqB2vprzbOTz75JJ7g1fuSLccee2zspDbaaKPFvjqNqi8l6best8GG+wrXXWovqGnn4ZJ7D9dnQgtNWtzIs3sJ13b61HDdpwaeAEDt+3bbbRebhHhwpfWBdRp1F2g12NCKQFgZbrjhwjHHHDPQvYTtvvnmm+Gxxx6L+839lZoW7rHcZ2jxoJaoshaKdfgcD+D0G+I4cG999NFHw5/+9Kcw0UQTxaDE/a+6aa6T5B5s+rONMws2hAvSZIpOa+NshJ/14IMPjv8JOL5Utzb6TyNJv2W9DTbVeIj93e9+F+6///5BuhiA6/qGG24YH2rplkCzDtd3Wg946CQUULu/ySabhKeffvqX6zTXetbNFroo0CLBNZ0H8crv1dpuJWpXeOAmXNE8xL2o0Tp8n5+T41AZgKqxbcIN92HKZr+4DxNqqMkijHVyqEHuwYYd7q82zjyCTZ5tnFQJttrGWQ//MTjxKYv/TNUduyRJA0sNNjzEcg/jYbLWwyM3f/qOUlNCqFh//fVjbT5NV9Skc12nqwLBgBoSHmC5N/Kgf9ppp8XafZa99tor1qLwIE9Iyb5OMxcDZyrvd5UISP/5z3/iPWSMMcYIxx9/fNNuCdwvaHL74IMPmj5M87k999wz3q8INrQyjD766PFY3nzzzXV/rk5RSB8bDlp2MhTVxoks2FBdxglDtRtLZXNQM53WxlkPnaapueIE41iw79bWSFJ9qcGmmcpgQ5MUD7hc77lOs3z00UfhkEMOiWGAexT3N75P9wNqcggjLNTsDDXUUPHn4+/Z16n52WOPPWI5tXD9px8qfXy4ZxLE8rof0MzE/ZcuJBw77ruEMbbHz85cPbTG9OU+298KCTaVenti9bWNE1mw4WDzJwGDhaYvOiozdK1ZlVmntXHWQ00QtVf0OzriiCM6+qSSpE7QH8GG636t+wwP6NybCCw0afEZWgguu+yycPHFF8eF+9R0000Xy6GvTvZ1HoKpoa8cBZxhXhn2iXKZOO/xxx9vWgPTW1kFA+GKQTzcQ+l+wc9BSwz9bBgsQwsE3UY4Dp2oY4JNtWZtnKCmgwBELQYJl/TKQefmT1JmfWZ9rAwOnAD8MrKlE9s4a6F6kzlw6JR93333WVsjSU0UFWwIKYxyZVg0NTa1pt3ges81e+ihh47NSrX05cGaaz4P84yk5R7HKw4YyMK9Kg+Uz8hj7qV0CeGBvDIw8X1aKOhSQRBjxDIP6J2oY4NNszZO0CxFMKE2h1846ZJaERJ0drLwS6BqDd3UxlmJ/zT0AyKh864O1pckNVZUsOH6fdxxx8UHaV45wP2qEvcspu6YYIIJYssD96ZaehtsslBBP1TuN7RQMBNwnv0sKYu+QYQW7pu1+n4SotZaa60wzDDDxGlLmH+uE3VssOkNftmElcqQwL+pDakcskZQ4ReSZxsn1XJFtXFWY5JDOnAxHw59jvJK6JJUZkXdf7jWEyx4KCa88OqEyusy9yCGfBNYNt9887pzvvQ22DAqmBoiRibR3YL7Wx7zs1WiuYl+QdQG0b+Gd0ZxP61E1wlqirJ51PK8n+epq4NNI/zSSdLUxFArk/VK7/Q2zmocL+bA4USi7xD9cooKUJLU7XgY5cGTYdbUumejVqntpoafrzMKt9a1vS/oP8nErNw7qLln/jbme2GbTGQ33njjxXsLD6b1uihw7yAo0GRFq0M9hBpqh/gcTV/co+hmccUVV/yyUENErU4r9yIGtTC0mxoZ+nSed955MXwRutgeo78Yzk6Ys49NG4INJy3b5aTjRKi33U5q46zG9uiARkct+vHQ/pln1aMklQ2v5qHGgRt0NuR6sMEGi7Xw1HrzdUb28IDaCsIKc5HRbMNDLi0BTMLKNtgW89sQdhp1UeABnBBGwKnX7eGtt96KfSu5h3I/IzBRc1O9TDXVVHG+tFaGYtOqwX2G5jNaI5gMlv0hoE0xxRRx0l1e6XP66ac37XrRTqUNNmyHuW+YGppamXrVdqltnISavNs4q9Exi7kE+NkY+k6osrZGkuqjloE+iXQVqLfQPJQ691klQgS1NAQKpu+gVp2J+2jSofMw96FWr9k0a/GSTcqutS/ZQu0RswS3+qDN9miGog8R3SzYLsdzm222iX1J6bPKZzr5XtS1wYbqNiYKojNudTUftTW8cJNqO9ImVXT1fgmd1MZZiZ+XalN+NubIoUN0rZ73kqRfUevAAItGC81VzUa99hblsE3KzMrOuj7kgXsBtSPV+1C9sF2CVh6BI9snOgdn5fN3vlZUt4s8FRJs+qONk1S65ZZbxrKpeqRc+s8QdqjloFMXVZCMxa98zUG1TmvjzHBsSMxUBzLzMk8FnZyQJUnqBIUEm/5o4yRR0iubdkVqUbJ2QAIN7YB8jVFNhJVGybzT2jgzJGRmLKYp7cADD+y3JjxJkrpZIcGmP9o4qb0gcDBx3QEHHBBngaRc2jd5USS9u2kGy6O6sb/bOMHoJ4YL8mZz3urdDdV/kiS1WyHBpr/aOAk3TPdMeyavXcjK5d+Ei7yabiinv9s4aZ+lPNo1ixp1JUlS2RTeeViSJKm/GGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGwkSVJpGGzUFoMNNtggi4rlMZf0W+CVTW3hTbb/ecwH8DgUw+OqTuGZp7bwItj/POYDeByK4XFVp/DMU1vkdRGsVU7ZlrwUWXY38TgUw+OqTuGZp7bI6yJYq5yyLXkpsuxu4nEohsdVncIzT22R10WwVjllW/JSZNndxONQDI+rOoVnntoir4tgrXLKtuSlyLK7icehGB5XdQrPPLVFXhfBWuWUbclLkWV3E49DMTyu6hSeeWqLvC6CeZXTKYrcnyLL7iYeh2J4XNUpPPPUFnldBPMqp1MUuT9Flt1NPA7F8LiqU3jmqS3yugjmVU6nKHJ/iiy7m3TDcaj1Mxa9tKqIMqUUnnlqi7wugnmV8/PPP4cffvghfP/99+Gnn37q+WrfUMaPP/4Yy/nuu+/iwt/7Ul5e+1NLkWV3k9TjUGu9Mi2tKqJMKYVnntoir4tgHuV89NFH4ZprrgnrrbdemHvuucOFF14Yvvrqq57v9s5nn30W7rrrrnDQQQeFVVZZJcw+++xhlllmCeuss04455xzwhtvvNGrgJPH/tRTZNndJPU41FqvTEuriihTSuGZp7bI6yLYSjnffPNNuPfee8Mee+wRZpxxxjD88MOHYYYZJhx99NHh888/7/lUc99++234xz/+EeaYY44wwQQThNlmmy3MO++8YcIJJwwjjjhimGSSScKuu+4a3nnnnZ416mtlf5opsuxuknocaq1XpqVVRZQppfDMU1vkdRFMLYdQc/bZZ4f5558/BpBlllkmTDPNNGHooYcORx11VJ+CDbU1++67b1h11VXDSSedFG666aYYmC6//PKw/PLLhxFGGCGMO+644eqrr45NU42k7k9vFFl2N0k9DrXWK9PSqiLKlFJ45qkt8roIppbzwQcfhI033jgsueSS4YILLgj3339/WGmllZKCDf1qXnvttbhUBxfKpUlqiCGGCAcccED49NNPe75TW+r+9EaRZXeT1ONQa73+XPJURPlFlCml8MxTW+R1EUwthwDy9NNPhxdffDHW3rz99tthtdVWSwo2jbz11lthqaWWiuVus8024f333+/5Tm2p+9MbRZbdTVKPQ+p6KYreVhHlF1GmlMIzT22R10WwlXLozMtIJtD/pYhg8+abb4bFFlssDDXUULFjsTU27Zd6HFLXS1H0tooov4gypRSeeWqLvC6CeZVTVLB56KGHwnTTTRdGGmmkcNlll9nHpgOkHofU9cDvPZsCoNbC97OQjd5uK5tigGkKsrJ6M2VBb8vviyLKlFJ45qkt8roI5lVOEcGGm8vuu+8eRh111LDwwgvHpq9m8tqfWoosu5ukHofU9ail22uvvWJfq3rLLrvsEt57772eNXq3rS+//DLccccd4eCDDw7LLrtsHI3HyLwVV1wxHHnkkbEfWT29Kb+viihTSuGZp7bI6yKYVzl5BxuewK+//vpYWzPRRBOF0047LfblaSav/amlyLK7SepxSF2PwLLuuuvGz88888xxKoDqZZ999hmo/1X1dlgqMRLvhBNOiPMuTTnllGGhhRYKK6ywQlwWXHDBMOecc4ZHHnmk59ODalZ+iiLKlFJ45qkt8roI5lVOnsGGpgFGQy2xxBKxtmbbbbcNr7zyykBNDfXktT+1FFl2N0k9DqnrvfvuuzHYDD744OH8888P99133yDLSy+9NFAzZaNt0dR0xhlnxPmRpphiinDooYeGe+65Jzz//PPhueeei3+n2bOyBqhao/JTFVGmlMIzT22R10Uwr3LyCjaEl0cffTSstdZacXK+NddcM/67Wd+aTF77U0uRZXeT1OOQul5lsGlUi1Kp0baeffbZ2PTEZJLHH398+PDDD3sVmis1Kj9VEWVKKTzz1BZ5XQTzKievYMOTN69RoKZmkUUWCQ8++GCvQw3y2p9aiiy7m6Qeh9T18gw21Aaee+65cYZrzi9qaPoaalCv/FYUUaaUwjNPbZHXRTCvcvIINsyFs91228WbznLLLRffHUWzQV/ktT+1FFl2N0k9DqnrVQabG2+8MZ4nLJ988knd0Uv1tsU6u+22W6wNpAmq2fQB9dQrvxVFlCml8MxTW+R1EcyrnFaDzauvvhp23nnn+HoGXqNwyy23xKG3fZXX/tRSZNndJPU4pK6XBRs+z5xGvCSVZe211w4HHnhgfP3G119/3fPpAaq3wwJepkpZww47bLjyyitjfxo6Ee+4445hyy23jLNb80qPL774In6+nnrlt6KIMqUUnnlqi7wugq2U8/HHH4cXXnjhlw6XSy+9dAw2e+65Z2wy4Ou8JqFZrQt9HPbff/8wzjjjxIWhvbwn6tprrx1k4SbXaI6RVvanmSLL7iapxyF1PTrx/uEPf4jvDKOmhYW/E05GHnnkOEz71FNPjcO3M/W2RQdhOqUz4SNNUQwVH3/88eM8ScMNN1wYZZRRYodiAg7nZT31ym9FEWVKKTzz1BZ5XQRbKefwww+PNwaG4E4//fSxXwzNBdwoZphhhvh13iXFiKZG6BzMPDW8D4oOndTaTDrppDUXXrxZeQOr1sr+NFNk2d0k9TikrkcfK4IyzVCcK0888US48847w1lnnRVft8F5x5DtW2+99Zf+WPW2RdhedNFFY7Dhpa0bbbRRfPEqQfqiiy4Km2yySRhvvPHCGGOMEUdgVdcEZeqV34oiypRSeOapLfK6CLZSzt///vf49EvzQL1lww03jNX/jfD9vffeu2lZLDfffHPDJqpW9qeZIsvuJqnHIXU9EFhYso6+dAL+6quvYk0h4Ybalu233/6XSfXqbasy2NAExSs7CMrffvttnCeJ7/NyV8qjyYp3ldVSr/xWFFGmlMIzT22R10WwlXKY5IxOnFz86y00IzQb1cRNimatZmWxcPNpNIqllf1ppsiyu0nqcUhdrxE6A++xxx6xeYpav6x2sN62KoPNddddF8+9Spyrxx57bGzimnjiicMzzzzT852B1Su/FUWUKaXwzFNb5HURzKucTlHk/hRZdjdJPQ6p6zVCJ1/6w9BHZr755ovTBaDetujztcYaa8QmT2azrtXUdMopp8RgQ1h6/PHHe746sHrlt6KIMqUUnnlqi7wugnmV0ymK3J8iy+4mqcchdb1GqLHZddddY2diRkplzZ71tkVTFVMKDD/88PHPytcwgI7uRx99dAxKvGahXv+weuW3oogypRSeeWqLvC6Ctcop25KXIsvuJqnHIWU9gsZjjz0WnnzyyUGajUAnYgIINSz0mcmGadfbFn1paGqiczAd3h944IGByn3xxRfjbNfU6Oy7776xibSWeuW3oogypRSeeWqLvC6Ctcop25KXIsvuJqnHIWU9OvYyLxIdhA877LD4Nm76vRBIss7r1NbwRm6GcmdTATTaFrNZ86JL+tmsvvrq4eqrr45lEpI23XTTMNZYY4W55porfq5WmEKj8lMVUaaUwjNPbZHXRbBWOWVb8lJk2d0k9TikrEcNCwGGjrzMccQQ7Zlmmim+9Z1pBcYcc8yw6qqrxtFRlZ3UG22LMs8555w4RJwmp8kmmyyWSdmjjz56mGeeeeLkff09+q6IMqUUnnlqi7wugrXKKduSlyLL7iapxyFlPUbA0Q+GWpX99tsvhpjFF188Tga5zTbbxLlmGOlEWKnUbFvMjM3s1oyoWmGFFeJUAsycTa0QNTUMJW+kWfkpiihTSuGZp7bI6yJYq5yyLXkpsuxuknocUtcj3FB7wnudmHmaYf9MDfDRRx/FUU21ZqLuzbbov0PnY14HQpmUzRQG9ZqfKvWm/L4qokwphWee2sKLYP/zmA+QehxS10tR9LaKKL+IMqUUnnlqCy+C/c9jPkDqcUhdL0XR2yqi/CLKlFJ45qkt8roI1iqnjEseiiq326Qeh9T1UhS9rSLKL6JMKYVnntomjwthrTLKuOShqHK7TepxSF0vRdHbKqL8IsqUUnjmqW3yuBDWKqOMSx6KKrfbpB6H1PVSFL2tIsovokwphWee2iaPC2GtMsq45KGocrtN6nFIXS9F0dsqovwiypRSeOapbfK4ENYqo4xLHooqtxulHIuUdVIVva0iyi+iTCmFZ57aJo8LYWoZzAHyxBNPxPfurLXWWmG22WYL0047bZy1dfPNNw9XXHFFnBMkFfOL7LPPPmGWWWaJ7/Q55JBD4jwmvZG6T80UVW43SjkWKeukKnpbRZRfRJlSCs88tU0eF8LUMp566qmw7rrrhgknnDC+d2e99dYL66yzTph11lnDaKONFoPOJZdcMsiMsL3BBGmsO9VUU4Vhhx02DDHEEGHLLbcMH374Yc8nGkvdp2aKKrcbpRyLlHVSFb2tIsovokwphWee2iaPC2FqGUxHv9FGG8U3KjMF/RtvvBGXu+++Oyy55JJhuOGGi29J5mt99fLLL4e11147vhto4YUXju/z2WKLLcIHH3zQ84nGUvepmaLK7UYpxyJlnVRFb6uI8osoU0rhmae2yeNCmFoG79ohtPBOHaa8z/AiQt7GPMYYY8Ram6effrrnO73zzTffhBNPPDFMMskkYaeddgp77bVXfNGhwaazpByLlHVSFb2tIsovokwphWee2iaPC2EeZVSiGYlgQhiZb7754gsK++Lxxx8PiyyySGzeuu+++2JIMth0npRjkbJOqqK3VUT5RZQppfDMU9vkcSHMo4xKvFCQvjYjjzxy2GGHHXrdLwb0x9l5553D1FNPHY4++ujwxRdfhGOOOcZg04FSjkXKOqmK3lYR5RdRppTCM09tk8eFsNUyXnnlldiR+LHHHguXXXZZWH311WMzFP1s7r///l69KTlz7bXXxpFVK664YmzCoonLYNOZUo5FyjqcA4yue/PNN8Prr7/ecKFplKZM9GZbfJbgzZu9WZdt8MZwAnZl82otvSm/r4ooU0rhmae2yeNC2EoZBI011lgjTDfddDGQTDTRRGHUUUcNyy67bLjmmmtijUtvEZBWWmml2LfmwgsvDF9//XX8usGmM6Uci5R1OIdojqS/1jTTTNNw4Ty8/fbbYz+vRtv66aefYhNp9VQFTC1AbeOpp54aXnvttfi5ehqVn6qIMqUUnnlqmzwuhK2UwZP07rvvHmtpWJZeeukwwwwzhHHHHTf+/dJLL42di5vhM8cdd1wcBcWwbp6csydmg01nSjkWKet8+eWX4YwzzggrrLBCWGKJJWouM888c5wWYMghhwy33nprrCVstK1nn302bLzxxvF8I8wQzv/whz/Esjh3J5544rD//vvH2pt6GpWfqogypRSeeWqbPC6ErZRB+GAiPQIHy0svvRSuvvrqsNpqq8WaG+a0YVg4k/nVQxkPPPBAHNY955xzxuHiPHFnDDadKeVYpKxDrQnNRdSwPPPMM4MsjzzySOyXxZQAdFbnHES9bdHMdNJJJ8VQQw0PE0lSW0jfMJpUDzrooBhuJptssvDwww/HdWqpV34riihTSuGZp7bJ40KYRxkZQgpPy3fddVcc1TT00EPHDsSNAglNTocddlgYb7zxwq677hpDDjeYbNljjz3ihH/MiUPoeeGFF8J3333Xs3Ztee5TpaLK7UYpxyJlnWZeffXVeG4QbBiNRw0P6m2LkLT99tuH4YcfPuy9997h448/jl/PZKPyhhlmmHDHHXf0fHVQ9cpvRRFlSik889Q2eVwI8yijGk+/m222WWweWGqppWJ/hXqo8WEyPm40E0wwQezrwJN0tvBkTRMD4YaZiBdbbLEYfhp1Si5in1BUud0o5VikrNMIQfqiiy4Kk046aZh77rljKMmaMOtti5C93XbbxfNtt912G6S56cknnwyLLrpoGH300cO9997b89VB1Su/FUWUKaXwzFPb5HEhzKOMavSR2XDDDeNT76qrrhr/XQ9P2DQ3rb/++rEjZ/VCx04C0hRTTBFWXnnlsO2228YmiP7u2Imiyu1GKcciZZ1GqO3jtR6EXt4rVtlZvd62qO07+eSTY2DmHWT0A8s6qmd9vQjY9OmhNqieeuW3oogypRSeeWqbPC6EKWVwc7jnnntik1M2vDZD4GDYNoGEdzwdeeSRcZbienjC5obEkzPNBNULL79k+Divb3j++edj00FlH5xaUvapN4oqtxulHIuUdRq56aabwpRTThkDyg033NDz1QEabevFF1+MgZumUjoPE2YeffTReK4xh9Icc8wRR/U16hvWqPxURZQppfDMU9vkcSFMKYNaFvrFcAPYdNNNw8UXXxw7cTJT8GmnnRbmnXfeWFuz0EILxar9RrUrzdh5uDOlHIuUdeqhEzDn3iijjBI22WSTQWoFG22LZkw6I2+11VZhrLHGirU3NIFynjGaj2Ce9dWpp1H5qYooU0rhmae2yeNCmFIGT7JMxjf//PPHt3vTTMQ8IvSBYajs+OOPH+ey4Ym60VNvb9AhlJuPb/fuLCnHImWdehjWTRih2ejcc88dpOaw2bboB3b88cfH6Qk4ZxkFRZPnAgssEE4//fTw3nvv9XyytmblpyiiTCmFZ57aJo8LYUoZWfMRb/U+5ZRTwi677BI22GCDOLkZo6DOPPPMOKKJp+pWMRJq6623DmeddVbTp+hMyj71RlHldqOUY5GyTi2ce8yfRAdg5p5hXprqWsFG22JIOKPtJp988hjA6XPzr3/9K750laYtQvqf//xn57HRb5ZnntomjwthK2VQpU/HSybq4ybA8umnn8avtdL8VIn+PIycqn6LeCOt7FMjRZXbjVKORco6tRCoaeYcfPDB46zEtfpw1dsWfbT222+/MPbYY8dh4oyw49ziXOb8ZTJAaoKYy4a/1wvT9cpvRRFlSik889Q2eVwI8yij0xS1T0WV241SjkXKOtVocsr6XdH0Sd+uWiG63raYdI+O7bz+4+abbx5k2gBCNPPbjDDCCGG55ZaL76CqpV75rSiiTCmFZ57aJo8LYR5ldJqi9qmocrtRyrFIWacaI+NoPqIZipqX6gn2MrW2RY3fVVddFfvlMEcS895UIySdcMIJ8e30TDL58ssv93xnYLXKb1URZUopPPPUNnlcCGuVUcYlD0WV241SjkXKOtX+8Y9/xA7rDPFmyoF6EzXW2xav+KCjMB3S6QBf3Q+MDur0EyM40VRVbw6meuW3oogypRSeeWqbPC6Etcoo45KHosrtRinHImWdStS4rLLKKnH0Eq9FoNmonnrb4r1QlMF0BIyIYp6lO++8MzzxxBPhxhtvjO+dYpQUwea88877ZfK+avXKb0URZUopPPPUNnlcCGuVUcYlD0WV241SjkXKOpVuu+22OLUAI5eobWnUQb3etph+gFqb5ZdfPnYQpq9NNhIqm66A2iBehvn+++/X7bBer/xWFFGmlMIzT22Tx4WwVhllXPJQVLndKOVYpKxTiYnzmFTv8MMPb/j+MTTaFs1PTz/9dKyR4cWr2VQFlH3EEUfEOXJokkoJTq0ookwphWee2iaPC2GtMsq45KGocrtRyrFIWacSzUJ0FmYem3p9azLNtkVoYYRV5VQFNG0xvLvZKzvQrPwURZQppfDMU9t4IexfHu9fpRyLlHVSFb2tIsovokwphWee2sYLYf/yeP8q5VikrJOq6G0VUX4RZUopPPPUNl4I+5fH+1cpx6LWOmVaWlVEmVIKzzy1jRfC/uXx/lXKsai1TpmWVhVRppTCM09t44Wwf3m8f5VyLGqtU6alVUWUKaXwzJP0m5NyE661TpmWVhVRppTCM0+SeqHWjbtMi1QWns2SJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0DDaSJKk0ShVsjj/++HDwwQeHl156Kfz00089X+1ujz76aNh9993Df/7zn/Dtt9/2fFWSJNXSUcHmxx9/jDfvr776Knz55Zfxz++++65hSPn+++/jelh00UXDLLPMEu69997www8/1FyXf3/zzTex/HoL6xWFnzfbP/b1559/7vnOr9gffn6+d9lll4VxxhknHHHEEeGLL7745XuV+HdWZqOFz7B9SZLKqiOCDTdmalnOOuussPHGG4d55503zDTTTGGhhRYK22+/fbj++uvD559/3vPpX33wwQfhr3/9a/jnP/8Z3nvvvbDRRhuFBRZYINxzzz3h1ltvDbvttlu48847BwoqL774Yth0003DrLPOGrdRvRCMjjnmmBh+8vbZZ5+FI488Mv6MbGufffYJH374Yc93ByDsXHLJJeGwww4LDz/8cLj66qvDtNNOG0477bTw/PPPh1NOOSWcfvrp4eOPP+5ZI4SLLrrolzIbLXzm3HPPDV9//XXPmpIklUtHBJvnnnsubLLJJmGSSSYJ88wzT1hppZXCiiuuGGacccYw+uijh7nnnjvWXFTXpNBMs+yyy8bP7brrrmGVVVYJc8wxR9h7773DfPPNF6affvpwzjnnxNqKzBNPPBF+97vfxVqQueaaKyy44IIDLQsvvHA49dRTC2n2ueWWW8Kcc84Zhh122DDYYIOFVVddNbz11ls93x3go48+Cn/+85/DZJNNFpZccsmwww47hKmmmiru05ZbbhlDzuabbx5ee+21njVCuPjii8NSSy01yL5kCyFuhBFGCGOMMUY47rjjYs2NJEll1BHBhtqV9ddfP9ZS8HdqJlhuuummsNhii4Xhhx8+rLXWWuGNN97oWWMAanFuu+22cOCBB8baCMLKiCOOGG/kW2+9dbj00kvjOllTFR5//PFYE7T00kuH6667Lvzvf/8baHnkkUfCu+++W7OJqBXU1qy99tphuummi0FsiCGGCCuvvHJ48803ez4xAE1F7Pt5550XNtxwwxhq2Kfxxx8/hri//e1v4cEHHxyoRolan8cee2yQfcmWQw89NIw11lhh8sknj8fU5ihJUll1RLDhpv/qq6/GmpXKQMHfqWEYc8wxYxPRk08+2fOdAegvw7r//e9/w+KLLx5rQggMBAeabAgo1f1RsmCz7rrrDhIqeosaD8p55plnetUfh5/zpJNOChNOOGFsBttiiy3C0EMPXTPYsM+USU3OIYccEiaeeOIw5JBDxoWmtrvvvnuQ49QI/XJ23HHHuD3CY+o+S5IGdcIJJ8SH6xdeeKFhf9BuwsM1rQRXXnllId0yitZRnYercfOmP8nYY48dm3Cefvrpnu8MwIm03Xbbhdlmmy0sscQSsW8OtRLLLbdcDEIrrLBCrJWp/MXkEWxoAqOpjOYu+gY1wj489NBDcZszzDBDuOGGG2LfmmGGGaZmsCGo0XzG52efffYY2CaYYIK4LzST0VRHUxV9ipph23fccUdch9BHk1U3nqSSVJRWB61wjebaftddd8UH6Wbrcl3mc1yL2R4L/R5Zr7cPrH1VOcCk0aAV9ovv0XLCQ/W+++4b70nZoJV6P1/1/mTHsKj9aaajgw39Teh7M8ooo8Rajvfff7/nOwOQKmneoe8JTVJ8lkBw1VVXxWHfBIELL7wwHuRMFmzoj0PgIFiwVH6mmfvvvz8GrfHGGy/W2jTCPuy1116xKYimNv5Num8UbOgQTVBj+DqdfflPQ7+ff//732G99dYLO+20U69CGbU11PrQT4ny6DjdrhNNkjoJN+Nag1bol8igFR6Kaw1aYeAG12gGbdAqwLo8PFKbfvvtt4dddtkl3o+4sVfj5v/AAw/ELgVc/+kTOvPMM8frMzUk9DfNG6HpxBNPjPc99o/7R/WDMYHmmmuuifcofj5+frp0MNjllVdeCWeffXZsdXjnnXd61hiAwENLylFHHRX7jPIwzv5w72U7tKZwDPv7vtNRweb1118Pzz77bHjqqafiQeaEod8MnX1JkJyIlfg3nYFZj1/M8ssvHw/sfffdF/udEFwIQ5XpOQs2NAstssgiYZlllonLGmusEU82gkr1dqr1NtiwXUZ0cTKxDT7L1w466KC6wYYTgI7B9JkhmBBm+FkZqcV/KP4jUlPVm34y1HCxj/TRoebL0VCSNAAhgq4B9QatMLiEEarVAYV7DvcaHjh33nnnsNpqq8UQQDChr+c000wTzjjjjHj9rsTD8wUXXBCDE9ucf/754zZXX331WOvD9i6//PKeT+eH+yGtC8MNN1wctMKglMrBJ+CB+uijj44/++9///sYzjgOdGMg5DFohYfq6vsdU6twLKjdYZAP9zQCDq0otLQQcgiAfak4yEPHBBuGblP7wsHkhJl00knDqKOOGjvMkpyrT5Ja1lxzzXgjp3NtVk1YjdBEmeOOO24MTRx8Rgtx8+dP5sJhiHXlqCjCCEEiW0jmJG3K4CSv/F5liCJUbbDBBmGKKaaIo7qywNQo2FRj3wlGJG6q+PqClE34Yp84Ia2tkaQBqJXg+lw5aIWHxptvvjkGDQat8MBbPWiFexE1M1zHCSncB7h/cBP/4x//GMMQD9uV9yD+fu2118YbPvc1Jl2lmwDbo0aEQSs8BL/88ss9a+SD2hL6Zk455ZQxfA011FBxQA59WitltVe0cBD2CDIjjTRS3DdqkzhGTKNSeR+m7K222ip+jnBDNwv2h32gpoZjx2hc7j/V2ytaxwSbTz/9NA5tZrQSC6lx6qmnjjdm+sxcccUVTWscOJk4qI0+xy+GGhfCDzd7qtE4walKI0HzSyL4ULMDfuEkXpqCTj755LhwUpK4aSI74IADfvk6c83wWRI+65155pkxATNC6+23347loS/Bhp+Xk4UmrMrQ1AzHk5NttNFGi31y+hqKJKnMqKWoN2iFbgAMWiGs1Bq0wk2dEaZMs5ENWmF6kay5prrWn6YfQg/3F/qtcD/oy/Uc3Nf4WVh6Mx0J5dPMRh9NRhX/6U9/ikGjVrBhn3kw5+ei5obpRrJBKwQUgh/7XPkzU0nAfXrkkUeO26mslSHIEZKooGBEb6OWjSJ0TLDhgNF8xEnBQpMU1XLc/Lk5U0PCweXgt4JfICdd5S+IfxMgbrzxxjgcm+3xi2Jb/DL322+/+MuhRoeFQEPy5WQmfWdf5wSi/wyhgpOP2iOqAHkCqDzR+xJsUjFp4UQTTfTLcbO2RpKa41rJQyk1+lw/qwetULPBQ3g2uINrPDdwHsCpFeHBmK4UlQM1qO2gNYIuDNTO9DXUgHsKIYOBMc364rAPPJwTvAgpdGmgXxA1S7WCDeGOewb7Q/nU0rBPrM/n+bkZ9FLZhEVrBd06smBTWaHA9pluhcE81BZRG9afOrbzcBZAmDmYg0cQYARUdQfiPH3yySexloMETvgg7PAz0N+FXxKjiliYF4bmJQIQfV+yr/MZftmcJHvuuWf8j0HHZtohSazZQpslw685Yagt4iTLc0JA+uLQOZqTmE7X1R2+JEm1cf2kOYYH2M0222yQjrYMwlhnnXXitZVJV/kM4YbwwL2B+9X555//Sw0GIYbpR+j2QK1N9WzzvcVM9DR9UevDfaYRHq6pqeeBfP/994/3zWOPPbZhsKG7A60l9DWlOY1Qx99pYqK/Ky0PlQGFbfB1aoHoJ8TPx75y76b5btttt43bY70i79u1dGywyXBAOBno+EQNCO2RRaF2hl8QwYZaGv5dS7POwwQJOgtTjceJRS0Q/YayhRN88MEHj0mX5jaSPik+D5xUjAojpdPp+F//+leuoUmSyqTWoBX6lhBQqmvbQTMLwYLaC2r16XBMkxW1MoQWujlw38pqZVif7gsEJUYZEQBosuJBnT4+POjSwZZ1uH7X09tgQxn0ASKYUANDTQ8/S6Ngwzq0HvAQTxMd6/PwzgM+D/x8nlqiylqobDvURNFywXGgHxHTodDsRYsBQYlBPNXHsGgdH2wYTkciJtgQFqp7c+eJE4se4yRQToLKX2KlZsGGxE8wYu6ZWgsds2jGYn2q/LbZZpvchvmxD3ToooaLKlH6HDX6zyJJv1X1Bq1wr+EmXdlZth7WZ+Qu94Vag1YIP8wiT2dkOg9z7+DBkxp9av3ZHg+hTFdCs1d2vSaMsG62MAybUVcEGx6EK79XuV0eyHntDs1AzGDP99Eo2FQjpPFz/uUvf2l4DCibcEOTFcGN/aKvEaGG+zZhrL9DDdoebOhoyy+M5prqmgV+wXTQYhgZtR9U81H9lYpfAlWH3OyzNJ3h52BINCcYvxiSer1A0CzYUDYplyrMWgvpnaYo/vOQkOkYnMcvn+1yvPjPQ40Q+9Pfw+wkqVtwP6k1aIUaGx4M6efZl0Erte4Z3HeYEJaHc8IGM8AzWzFNV8zsS98VtkkwoIaEYML9gJofBqRkg1OYD43+KlmLQvZ1mrmYHJAHcQIOtT88PFPzVNnC0Zdgw32DJjeCX/W9shqfo+sFoZBgw7FjuDzNddxH61UQFKntwYa2PTo1MTkSNQ207XGz55fK5HQkYX6RfD+101WGXxYpkloT2g4JVFTp0WmYN4Fn/WY4gRq1g/L+JeY9oImJEUt9VVTnYZI1ZfMEQBisTP+SpIFxP6kctELNOSNw6aPIvYAOwjwMZ7UeKSqDDQ+19D/hvsfDNAsPttlEqnS3ICjwfYZY86CdDU7hus6gFR5a+Xv2dWp+9thjj1gOTWq0AvBwS40T5Wf6Emx6i2Ym7qnUdhFk6FtEGGNuH352RhoTtNif/tT2YMMvnU63TE5EDQjhgsBAgmVINf1RGAdf/UtKQY0QSZfUy4RCDMVmW/ybbZM4Sc90kGoUoAhIhIbeDrurxknMSc5/nuq3e7eCkEUQzJrSelONKkkagAdBakuYq4xrKQ+gdBWgpj1VZbBhsEmt2nnCE0GAwEKLAJ/h/sL8Z9nglMMPPzzeryiHvjrZ16kM4KGf8MCM+wxTZ+4aanGyASssTCBIcxiVBNSkUJvTrDaqkawTNeGKiQrpo8T9kPs0AYt+Ntl7Hvv75cttDzacSNyA+WXSK5tqQSbaI/FRg/P3v/891uC08gvIsC3SMomcnuKcbGyHk4CwwaRCnMC12knzxERMbJO5c+iPkxf+I9DRmk5pnFjW1khS39EEQ6AhCBBwWhm0QkhhJl8Gi1BjU2tQCn1aeNimiwKBpJZmnYfpX8lw8Kz/ZvWgFb7G96i1oeKAfjH1ttUM9xZmV6a2iFot7tGVlQF8n2NG7RFBjFBF94z+0jGdhwkT1ISw85xULNz0+VqeQYMDTqqk5zdVkGyHKjxONhJlf4QB2hyzbbbStFYtq9bkGBYdziSprBi0QgdcbsoEgFYGrXCNP+6442LtBd0P6JNTiXsOM8wzDxqjq6j5qKVZsKG/EP1QqwerZAsdpOmrynsLGS3FVCSMYErBfZnWDY4P4aXW8eF+ysSA1HrxaoY8H+Kb6ZhgI0lSf+AhkH6ctQatgKYh+lESBJgPppVBKwQXWgPo8kB4oca+slmGFguGfBNYCFPUvNTSLNgQoPg5KweqVC60StBNgWHs9BPlwT61ewfrUR61P9QGcRyrm9jor8TLMKn1ou8nlQn9xWAjSfpNoT/KEUccUXPQCkOkGR1FbQThptVBK2CQCN0PKJMRtcxsTG0JTUFMZJc1HTEHWb3admYSJijQZFVrNG4zeXceZuI+RhBTI8NcbBw3whehi9FkjP6iAzZh7jfXx0aSpP7ETZZBK4werTdohRFKTNiXWqtRibDCq21otsnmrWFINgNY6KfCKCbCTqOaIfqZ0neSgJMyhJoh5vTzoRkqj/ngCIf0s6H5jOPFccsG5HA8mZyWFzgz7UgrNV4pDDaSpN8UmoeqB63QHyQbtML8MNSo5DFoJUMYoUxeMskcM8xyz8R9NOnQeZimmiL7ePL6HoZm0w+n0XQmfcExpBmKPkS8YoJ9ogMzHa95kSjDwflMf/RdrWSwkST9JvXXoJUMZVLTwSCPyoErtYaA542+RGyPAJXnoJVsnzhulceQr+W5nb4w2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpNIw2EiSpJII4f++JF+5mDY2GgAAAABJRU5ErkJggg=="
width=600
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transpose-Matrices">Transpose Matrices<a class="anchor-link" href="#Transpose-Matrices">&#182;</a></h3><div class="highlight"><pre><span></span><span class="c1"># matrix m transpose</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">]])</span>
<span class="n">m_t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="c1"># [[1, 4], [2, 5], [3, 6]]</span>
</pre></div>
<h3 id="Neural-Networks-Concept-Viewed-as-a-Graph">Neural Networks Concept Viewed as a Graph<a class="anchor-link" href="#Neural-Networks-Concept-Viewed-as-a-Graph">&#182;</a></h3><ul>
<li><strong>Neurons</strong> are like nodes in a graph.</li>
<li><strong>Weights</strong> are like edges connecting the nodes.</li>
<li><strong>Activation functions</strong> are like the nodes' output functions.</li>
<li><strong>Loss functions</strong> are like the cost functions.</li>
<li><strong>Optimizers</strong> are like the algorithms to minimize the cost functions.</li>
</ul>
<h3 id="Useful-Analogy:-Comparing-TensorFlow-Neural-Networks-to-Execution-Graphs">Useful Analogy: Comparing TensorFlow Neural Networks to Execution Graphs<a class="anchor-link" href="#Useful-Analogy:-Comparing-TensorFlow-Neural-Networks-to-Execution-Graphs">&#182;</a></h3><table>
<thead><tr>
<th>Aspect</th>
<th>Neural Network</th>
<th>Execution Graph</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Structure</strong></td>
<td>Layers (input, hidden, output) connected by weights.</td>
<td>Visual representation of computations.</td>
</tr>
<tr>
<td><strong>Nodes</strong></td>
<td>Neurons that perform computations.</td>
<td>Operations (e.g., addition, multiplication).</td>
</tr>
<tr>
<td><strong>Edges</strong></td>
<td>Weights that connect neurons.</td>
<td>Data paths that carry datastructures between operations.</td>
</tr>
<tr>
<td><strong>Data Flow</strong></td>
<td>Data (tensors) flows from the input layer, through hidden layers, to the output layer.</td>
<td>Data flows from one operation to another, following the graph's structure.</td>
</tr>
<tr>
<td><strong>Training</strong></td>
<td>Adjusts the weights to minimize error.</td>
<td>Updates the graph's parameters to optimize performance.</td>
</tr>
<tr>
<td><strong>Example</strong></td>
<td><code>Input Layer -&gt; Hidden Layer -&gt; Output Layer</code></td>
<td><code>Operation A -&gt; Operation B -&gt; Operation C</code></td>
</tr>
<tr>
<td><strong>Visual Representation</strong></td>
<td><code>Input -&gt; [Weights] -&gt; Hidden -&gt; [Weights] -&gt; Output</code></td>
<td><code>Node A -&gt; [Data] -&gt; Node B -&gt; [Data] -&gt; Node C</code></td>
</tr>
</tbody>
</table>
<h3 id="Why-Activation-Functions-applied-to-the-tensors?">Why Activation Functions applied to the tensors?<a class="anchor-link" href="#Why-Activation-Functions-applied-to-the-tensors?">&#182;</a></h3><p>Activation functions are applied to tensors at each layer of a neural network. They bring non-linearity to the model. The most common activation functions used in DL:</p>
<ol>
<li>Sigmoid: <code>tf.keras.activations.sigmoid</code> (0-1) used in the output layer of a binary classification problem.</li>
<li>Tanh: <code>tf.keras.activations.tanh</code> (-1-1)</li>
<li>ReLU: <code>tf.keras.activations.relu</code> (0 to infinity) is used in hidden layers of a neural network.</li>
<li>Leaky ReLU: <code>tf.keras.activations.relu</code> (0 to infinity)</li>
<li>Softmax: <code>tf.keras.activations.softmax</code> (0-1)  used in the output layer of a multi-class classification problem.<br>
As well as implementation in python (numpy):
```python
def sigmoid(x): return 1 / (1 + np.exp(-x))</li>
</ol>
<p>def relu(x): return np.maximum(0, x)</p>
<p>def softmax(x): exp_x = np.exp(x); return exp_x / exp_x.sum()</p>

<pre><code>
### Loss Functions
Loss functions are used to measure the error/performance between the predicted value and actual value. The loss function is used to update the weights of the model to minimize the error. The loss function is used to update the weights of the model to minimize the error. Here are the most common loss functions used in DL:

1. Mean Squared Error: `tf.keras.losses.mean_squared_error`
2. Binary Crossentropy: `tf.keras.losses.binary_crossentropy`
3. Categorical Crossentropy: `tf.keras.losses.categorical_crossentropy`
4. Sparse Categorical Crossentropy: `tf.keras.losses.sparse_categorical_crossentropy`
5. Hinge: `tf.keras.losses.hinge`

Implementing MSE in python (numpy):
```python
def mean_squared_error(y_true, y_pred):
    return np.mean(np.square(y_true - y_pred))</code></pre>
<h3 id="Optimizers">Optimizers<a class="anchor-link" href="#Optimizers">&#182;</a></h3><p>Optimizers are used to update the weights of the model to minimize the error (minimize the loss function).
 Here are the most common optimizers used in DL:</p>
<ol>
<li>SGD: <code>tf.keras.optimizers.SGD</code></li>
<li>RMSprop: <code>tf.keras.optimizers.RMSprop</code></li>
<li>Adagrad: <code>tf.keras.optimizers.Adagrad</code></li>
<li>Adadelta: <code>tf.keras.optimizers.Adadelta</code></li>
<li>Adam: <code>tf.keras.optimizers.Adam</code></li>
</ol>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gradient_descent</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span>

<span class="k">def</span> <span class="nf">adam</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">beta1</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">beta2</span><span class="o">=</span><span class="mf">0.999</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">):</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">beta1</span> <span class="o">*</span> <span class="n">m</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">v</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">gradients</span><span class="o">**</span><span class="mi">2</span>
    <span class="n">m_hat</span> <span class="o">=</span> <span class="n">m</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span><span class="p">)</span>
    <span class="n">v_hat</span> <span class="o">=</span> <span class="n">v</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">m_hat</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">v_hat</span><span class="p">)</span> <span class="o">+</span> <span class="n">epsilon</span><span class="p">)</span>
</pre></div>
<h3 id="Regularization">Regularization<a class="anchor-link" href="#Regularization">&#182;</a></h3><p>Regularization reduces model complexity and prevents overfitting by adding a penalty to the loss function.</p>
<p><strong>Types of Regularization</strong>:</p>
<ul>
<li><strong>L1 Regularization</strong>: Adds a penalty equal to the absolute value of coefficients.<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L1</span><span class="p">(</span><span class="n">l1</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</li>
<li><strong>L2 Regularization</strong>: Adds a penalty equal to the square of coefficients.<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L2</span><span class="p">(</span><span class="n">l2</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</li>
<li><strong>L1 and L2 Regularization</strong>: Combines both L1 and L2 penalties.<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L1L2</span><span class="p">(</span><span class="n">l1</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">l2</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
</pre></div>
</li>
</ul>
<p><strong>Usage in Layers</strong>:</p>
<ul>
<li>Apply regularization to layers like Dense, Conv2D.<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span>
      <span class="n">kernel_regularizer</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">regularizers</span><span class="o">.</span><span class="n">L2</span><span class="p">(</span><span class="mf">0.01</span><span class="p">)),</span>
      <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">)</span>
<span class="p">])</span>
</pre></div>
</li>
</ul>
<p><strong>Impact on Training</strong>:</p>
<ul>
<li>Regularization terms are added to the loss function to control model complexity.</li>
</ul>
<p><strong>Hyperparameter Tuning</strong>:</p>
<ul>
<li>Adjust <code>l1</code>, <code>l2</code> to balance underfitting and overfitting.</li>
</ul>
<p><strong>Dropout</strong>:</p>
<ul>
<li>Randomly ignore neurons during training.<div class="highlight"><pre><span></span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
</pre></div>
</li>
</ul>
<h3 id="Backpropagation">Backpropagation<a class="anchor-link" href="#Backpropagation">&#182;</a></h3><p>Backpropagation updates neural network weights by calculating the gradient of the loss function.</p>
<div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">backpropagation</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">gradients</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">weights</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span>
</pre></div>
<h1 id="Mathematics">Mathematics<a class="anchor-link" href="#Mathematics">&#182;</a></h1><h3 id="Traversing-Neural-Network-with-Mathematical-Operations">Traversing Neural Network with Mathematical Operations<a class="anchor-link" href="#Traversing-Neural-Network-with-Mathematical-Operations">&#182;</a></h3><p>A neural network can be represented mathematically using matrices and vectors.</p>
$$\
\mathbf{b}_2 = \begin{bmatrix}
b_{21} \\
b_{22} \\
\vdots \\
b_{210}
\end{bmatrix}
\
$$<h3 id="Neural-Network-Tree-Representation">Neural Network Tree Representation<a class="anchor-link" href="#Neural-Network-Tree-Representation">&#182;</a></h3><p>forward propagation in a neural network can be represented as a tree structure with three layers: input, hidden, and output.
Here is the graph over a simple neural network with one hidden layer mathematical operations  for each node and edge are included.</p>

<pre><code>plaintext
    A1 A2 A3          Input layer
     \\| |//
      \|X|/
      B1 B2           Hidden Layer
       \ /
        C1            Output Layer</code></pre>
<h3 id="Pseudocode">Pseudocode<a class="anchor-link" href="#Pseudocode">&#182;</a></h3><p>Define the input layer.
Define the hidden layer with a specified number of neurons and an activation function.
Define the output layer with the number of neurons corresponding to the number of classes and an activation function.
Compile the model with a loss function and an optimizer.
Train the model on the dataset.</p>
<h3 id="Mathematical-Representation-using-Matrices">Mathematical Representation using Matrices<a class="anchor-link" href="#Mathematical-Representation-using-Matrices">&#182;</a></h3><p><strong>Iput Layer</strong>:</p>
<ul>
<li><strong>Neurons</strong>: Nodes that receive input data.
$$ \mathbf{x} \in \mathbb{R}^{784} $$
<strong>Hidden Layer</strong>:</li>
<li>Weights: $ \mathbf{W}_1 \in \mathbb{R}^{784 \times 128} $
  $$
  \mathbf{W}_1 = \begin{bmatrix}
  w_{11} &amp; w_{12} &amp; \cdots &amp; w_{1,128} \\
  w_{21} &amp; w_{22} &amp; \cdots &amp; w_{2,128} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  w_{784,1} &amp; w_{784,2} &amp; \cdots &amp; w_{784,128}
  \end{bmatrix}
  $$</li>
<li>Biases:
  $$
  \mathbf{b}_1 = \begin{bmatrix}
  b_{11} \\
  b_{12} \\
  \vdots \\
  b_{128}
  \end{bmatrix}
  $$</li>
<li>Activation:
  $$
  \mathbf{h} = \text{ReLU}(\mathbf{W}_1 \mathbf{x} + \mathbf{b}_1)
  $$</li>
</ul>
<p><strong>Output Layer</strong>:
    $$   \mathbf{y} = \text{softmax}(\mathbf{W}_2 \mathbf{h} + \mathbf{b}_2)  $$</p>
<h3 id="Explanation-Beyond-the-Maths">Explanation Beyond the Maths<a class="anchor-link" href="#Explanation-Beyond-the-Maths">&#182;</a></h3><ul>
<li><strong>Input Layer</strong>: Takes an input vector $ \ \mathbf{x} \ $ of size 784.</li>
<li><strong>Hidden Layer</strong>: Applies a linear transformation followed by a ReLU activation function.</li>
<li><strong>Output Layer</strong>: Applies another linear transformation followed by a softmax activation function to produce a probability distribution over the 10 classes.</li>
</ul>
<h3 id="Neural-Network-Layers">Neural Network Layers<a class="anchor-link" href="#Neural-Network-Layers">&#182;</a></h3><table>
<thead><tr>
<th>Layer</th>
<th>Pseudocode</th>
<th>Mathematical Representation</th>
<th>Explanation Beyond the Maths</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Input Layer</strong></td>
<td><code>x = np.random.randn(input_size)</code></td>
<td>$$ \mathbf{x} \in \mathbb{R}^{784} $$</td>
<td>Takes an input vector ( \mathbf{x} ) of size 784, representing a 28x28 pixel image.</td>
</tr>
<tr>
<td><strong>Hidden Layer</strong></td>
<td><code>h = relu(np.dot(x, weight1) + bias1)</code></td>
<td>$$ \mathbf{h} = \text{ReLU}(\mathbf{W}_1 \mathbf{x} + \mathbf{b}_1) $$</td>
<td>Applies a linear transformation followed by a ReLU activation function.</td>
</tr>
<tr>
<td><strong>Output Layer</strong></td>
<td><code>y = softmax(np.dot(h, weight2) + bias2)</code></td>
<td>$$ \mathbf{y} = \text{softmax}(\mathbf{W}_2 \mathbf{h} + \mathbf{b}_2) $$</td>
<td>Applies another linear transformation followed by a softmax activation function.</td>
</tr>
</tbody>
</table>
<h3 id="Mathematical-Representation-Details">Mathematical Representation Details<a class="anchor-link" href="#Mathematical-Representation-Details">&#182;</a></h3><table>
<thead><tr>
<th>Component</th>
<th>Pseudocode</th>
<th>Mathematical Representation</th>
<th>Explanation Beyond the Maths</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Weights (Hidden Layer)</strong></td>
<td><code>weight1 = np.random.randn(input_size, hidden_layer_size)</code></td>
<td>$$ \mathbf{W}_1 \in \mathbb{R}^{784 \times 128} $$</td>
<td>Matrix of weights connecting the input layer to the hidden layer.</td>
</tr>
<tr>
<td><strong>Biases (Hidden Layer)</strong></td>
<td><code>bias1 = np.random.randn(hidden_layer_size)</code></td>
<td>$$ \mathbf{b}_1 \in \mathbb{R}^{128} $$</td>
<td>Bias vector added to the hidden layer.</td>
</tr>
<tr>
<td><strong>Weights (Output Layer)</strong></td>
<td><code>weight2 = np.random.randn(hidden_layer_size, output_size)</code></td>
<td>$$ \mathbf{W}_2 \in \mathbb{R}^{128 \times 10} $$</td>
<td>Matrix of weights connecting the hidden layer to the output layer.</td>
</tr>
<tr>
<td><strong>Biases (Output Layer)</strong></td>
<td><code>bias2 = np.random.randn(output_size)</code></td>
<td>$$ \mathbf{b}_2 \in \mathbb{R}^{10} $$</td>
<td>Bias vector added to the output layer.</td>
</tr>
</tbody>
</table>
<h3 id="Example">Example<a class="anchor-link" href="#Example">&#182;</a></h3><p>For a digit recognition problem, the input layer receives a 784-dimensional vector representing a 28x28 pixel image. The hidden layer applies a linear transformation followed by a ReLU activation function. The output layer applies another linear transformation followed by a softmax activation function to produce a probability distribution over the 10 classes (digits 0-9).</p>
<h3 id="Training-a-Neural-Network">Training a Neural Network<a class="anchor-link" href="#Training-a-Neural-Network">&#182;</a></h3><p>Training involves feeding input data through the network.</p>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Define the input layer</span>
<span class="n">input_size</span> <span class="o">=</span> <span class="mi">784</span>
<span class="n">hidden_layer_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">output_size</span> <span class="o">=</span> <span class="mi">10</span>

<span class="c1"># Initialize weights and biases</span>
<span class="n">weight1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_layer_size</span><span class="p">)</span>  <span class="c1"># Weights for input to hidden layer</span>
<span class="n">bias1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">)</span>  <span class="c1"># Biases for hidden layer</span>

<span class="n">weight2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">hidden_layer_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">)</span>  <span class="c1"># Weights for hidden to output layer</span>
<span class="n">bias2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">output_size</span><span class="p">)</span>  <span class="c1"># Biases for output layer</span>

<span class="c1"># Forward pass</span>
<span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">exp_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">exp_x</span> <span class="o">/</span> <span class="n">exp_x</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Input vector</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_size</span><span class="p">)</span>
<span class="c1"># Hidden layer computation</span>
<span class="n">h</span> <span class="o">=</span> <span class="n">relu</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">weight1</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias1</span><span class="p">)</span>
<span class="c1"># Output layer computation</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">weight2</span><span class="p">)</span> <span class="o">+</span> <span class="n">bias2</span><span class="p">)</span>
</pre></div>
<h3 id="Conclusion">Conclusion<a class="anchor-link" href="#Conclusion">&#182;</a></h3><p>Deep Learning is a subset of Machine Learning that uses neural networks to model complex patterns in data. It involves activation functions, loss functions, optimizers, regularization, backpropagation, and training. Mostly built using linear algebra translated to Python.</p>

</div>
</div>
</div>
 

</body>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
                </article>
            </aside><!-- /#featured -->
                <section id="content" class="body">
                    <h1>Other articles</h1>
                    <hr />
                    <ol id="posts-list" class="hfeed">

            <li><article class="hentry">
                <header>
                    <h1><a href="/some-dl-pt2-back-propagation.html" rel="bookmark"
                           title="Permalink to Some DL Pt2. Back Propagation.">Some DL Pt2. Back Propagation.</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2024-10-21T00:00:00+02:00">
                Published: Mon 21 October 2024
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Backpropagation">Backpropagation<a class="anchor-link" href="#Backpropagation">&#182;</a></h3><p>When in ml you get the error you need to update parameters (weights and biases) in order to minimize it. This is done by using the gradient of the error with respect to the parameters. This is done by using the chain rule of calculus:
function f(g(x)) has partial derivatives with respect to x f'(g(x)) * g'(x).</p>
                <a class="readmore" href="/some-dl-pt2-back-propagation.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/regression.html" rel="bookmark"
                           title="Permalink to Regression">Regression</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-11-06T00:00:00+01:00">
                Published: Mon 06 November 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Intro">Intro<a class="anchor-link" href="#Intro">&#182;</a></h3><p>Regression is a supervised learning problem: labelled data passed to a model, once model is instantiated some new input data can be passed in to predict what may happen next is a continuious sequence.</p>
<p>The simplest model is a line. A line is a rough generalization that gives the ability to explain and predict variables that have a linear relationship with each other. A line that fits a set of data best is a Linear Regression. In regression problems, we are trying to predict a continuous-valued output: housing price is the most known dataset.</p>
                <a class="readmore" href="/regression.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/scikit-learn-chunks.html" rel="bookmark"
                           title="Permalink to Scikit-Learn Chunks">Scikit-Learn Chunks</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-09-08T00:00:00+02:00">
                Published: Fri 08 September 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                None
                <a class="readmore" href="/scikit-learn-chunks.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/data-visualization-python.html" rel="bookmark"
                           title="Permalink to Data Visualization (Python)">Data Visualization (Python)</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-06-25T00:00:00+02:00">
                Published: Sun 25 June 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Data-Visualization-With-Python">Data Visualization With Python<a class="anchor-link" href="#Data-Visualization-With-Python">&#182;</a></h3><p>There are a lot of good code that makes it easy to tell a story with your data.</p>
<h3 id="Libraries">Libraries<a class="anchor-link" href="#Libraries">&#182;</a></h3><p>I list some popular libraries to deal with:</p>
<ol>
<li>matplotlib</li>
<li>seaborn</li>
<li>plotly
...</li>
</ol>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Example-1">Example 1<a class="anchor-link" href="#Example-1">&#182;</a></h3><p>I have written a sript a while ago to plot a long sequence of data. In this first example I plot data represented LIDAR scanning  of a road with segments having either cleanded ditches or not, while registering a lot I am intrested here in representing three quantitative variables extracted from LIDAR pointcloud.</p>
                <a class="readmore" href="/data-visualization-python.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/html-from-100days-of-web.html" rel="bookmark"
                           title="Permalink to HTML (From 100Days of Web)">HTML (From 100Days of Web)</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-06-25T00:00:00+02:00">
                Published: Sun 25 June 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Intro">Intro<a class="anchor-link" href="#Intro">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
                <a class="readmore" href="/html-from-100days-of-web.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/numpy-cool-library.html" rel="bookmark"
                           title="Permalink to Numpy (Cool library)">Numpy (Cool library)</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-06-10T00:00:00+02:00">
                Published: Sat 10 June 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Numpy-Intro">Numpy Intro<a class="anchor-link" href="#Numpy-Intro">&#182;</a></h3><p>No need to say a lot here, NumPy is useful and you need it all over the place.
In my favorite book about Data Science Jake says "provides an efficient interface to store and operate on dense data buffers." and then make a survey of many goodies fo numpy library. <a href="https://jakevdp.github.io/PythonDataScienceHandbook/02.00-introduction-to-numpy.html">VanderPlas, Jake. <em>Python Data Science Handbook</em>
                <a class="readmore" href="/numpy-cool-library.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/clustering.html" rel="bookmark"
                           title="Permalink to Clustering">Clustering</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-06-06T00:00:00+02:00">
                Published: Tue 06 June 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Intro">Intro<a class="anchor-link" href="#Intro">&#182;</a></h3><p>Cluster analysis is the method in data analysis that is used to classify data points. Clustering pick out pattern in unlabeled data and group items in meaningful way. As a programmer you have to write scripts that learns the inherent structure of the data with no labeled examples provided (unsupervised learning). The program under the hood analyzes the data it encounters and tries to identify patterns and group the data on output.</p>
                <a class="readmore" href="/clustering.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/perlin-noise.html" rel="bookmark"
                           title="Permalink to Perlin Noise">Perlin Noise</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2023-05-27T12:00:00+02:00">
                Published: Sat 27 May 2023
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Perlin-Noise-Algoritm">Perlin Noise Algoritm<a class="anchor-link" href="#Perlin-Noise-Algoritm">&#182;</a></h3><p>Ken Perlin is the creator of perlin noise algoritm used in generating textures and terrain-like images to name a few applications of this smooth noise. This arcticle is about application of it and not so much about the algorithms steps.</p>
<h3 id="Perlin-in-Python">Perlin in Python<a class="anchor-link" href="#Perlin-in-Python">&#182;</a></h3><p>In Python in 2023 there is no built-in implementation of the Perlin noise algorithm. Since I can't quickly (time isn't a key factor) refactor this implementation from java to python <a href="https://mrl.cs.nyu.edu/~perlin/noise/">https://mrl.cs.nyu.edu/~perlin/noise/</a>
                <a class="readmore" href="/perlin-noise.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>

            <li><article class="hentry">
                <header>
                    <h1><a href="/understanding-probability-with-python.html" rel="bookmark"
                           title="Permalink to Understanding Probability With Python">Understanding Probability With Python</a></h1>
                </header>

                <div class="entry-content">
<footer class="post-info">
        <abbr class="published" title="2022-12-09T00:00:00+01:00">
                Published: Fri 09 December 2022
        </abbr>

        <address class="vcard author">
                By                         <a class="url fn" href="/author/alex.html">Alex</a>
        </address>
<p>In <a href="/category/python.html">python</a>.</p>

</footer><!-- /.post-info -->                <div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Probability is a branch of mathematics that is often used to make decisions and is concerned with measuring uncertainty.</p>
<h3 id="Introduction">Introduction<a class="anchor-link" href="#Introduction">&#182;</a></h3><h4 id="Sets">Sets<a class="anchor-link" href="#Sets">&#182;</a></h4><p>Set data types in Python have rules similar to set in mathematics: collections are unordered, unchangeable (only removal or addition is applicable), store unique items, and are unindexed.</p>
<h4 id="Experiments-and-Event">Experiments and Event<a class="anchor-link" href="#Experiments-and-Event">&#182;</a></h4><p>Experiment return values for observation(s), and observations have some level of uncertainty. Single possible outcome of an experiment is a sample point in a set called sample space. Set sample space stores all possible sample points for one experiment. If your experiment is a set of n sample points the full sample space is written as follows for example of coin flip:</p>
                <a class="readmore" href="/understanding-probability-with-python.html">read more</a>
                </div><!-- /.entry-content -->
            </article></li>
                </ol><!-- /#posts-list -->
<p class="paginator">
    Page 1 / 2
        <a href="/category/python2.html">&raquo;</a>
        <a href="/category/python2.html">&#8649;</a>
</p>
                </section><!-- /#content -->
        <section id="extras" class="body">
                <div class="blogroll">
                        <h2>links</h2>
                        <ul>
                            <li><a href="https://getpelican.com/">Pelican</a></li>
                            <li><a href="https://www.python.org/">Python.org</a></li>
                            <li><a href="https://palletsprojects.com/p/jinja/">Jinja2</a></li>
                        </ul>
                </div><!-- /.blogroll -->
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="#">You can add links in your config file</a></li>
                            <li><a href="#">Another social link</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <address id="about" class="vcard body">
                Proudly powered by <a href="https://getpelican.com/">Pelican</a>, which takes great advantage of <a href="https://www.python.org/">Python</a>.
                </address><!-- /#about -->

                <p>The theme is by <a href="https://www.smashingmagazine.com/2009/08/designing-a-html-5-layout-from-scratch/">Smashing Magazine</a>, thanks!</p>
        </footer><!-- /#contentinfo -->

</body>
</html>