{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- title: Data QA Using Python\n",
    "- author: Alex\n",
    "- date: 2025-10-26\n",
    "- category: python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data QA Using Python \n",
    "A data quality analysis (QA) problem over a table using pandas without drowning in code.Let’s discover a systematic QA analysis, step-by-step.\n",
    "\n",
    "You have a table ith these columns:\n",
    "\n",
    "| A | B | C | width | D | Region |\n",
    "\n",
    "Each row represents record. Region groups related records geografically.\n",
    "\n",
    "A, B, C, width, and D are attributes to test for completeness, consistency, and validity.\n",
    "\n",
    "### Domain Knowledge\n",
    "\n",
    "Sometimes you need to have some domain knowledge i.e. in this example the width cannot be too small. It can be some other rules like if I have noticed:\n",
    "\n",
    "A → sometimes empty\n",
    "\n",
    "B → often empty\n",
    "\n",
    "C → may have false positives\n",
    "\n",
    "width → presumably numeric (complete?)\n",
    "\n",
    "Region → categorical, useful for grouping\n",
    "\n",
    "D (another attribute?) → complete in some Region groups\n",
    "\n",
    "\n",
    "###  Objective\n",
    "Goal is to measure how good or reliable this data is according to some rules - generally get a sense of completeness, validity, uniqueness, and consistency.\n",
    "\n",
    "- Detect missing data (A, B, width)\n",
    "\n",
    "- Flag possible false positives in C\n",
    "\n",
    "- Check completeness of D per Region\n",
    "\n",
    "- Summarize QA metrics per region\n",
    "\n",
    "All this is a form of data quality assessment — which is a component of profiling which probably is the topic for future post. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Metrics\n",
    "\n",
    "\n",
    "|       Check       |                  What it shows                  |           Example          |\n",
    "|:-----------------:|:-----------------------------------------------:|:--------------------------:|\n",
    "| Count / Missing % | How much data is missing                        | df.isna().sum()            |\n",
    "| Distinct count    | How varied the data is                          | df.nunique()               |\n",
    "| Type validation   | Whether the column values follow expected types | e.g., A numeric, C boolean |\n",
    "| Range check       | Are numeric values within expected bounds       | e.g., width > 0            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design  Python (pandas) QA Analysis\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Load your data ---\n",
    "# df = pd.read_csv(\"your_table.csv\")  # or from SQL / Excel\n",
    "# Example structure:\n",
    "# Columns: A, B, C, width, D, Region\n",
    "\n",
    "import click\n",
    "\n",
    "# --- 1 Basic completeness checks ---\n",
    "completeness = df.isnull().mean().to_frame(\"missing_pct\") * 100\n",
    "completeness[\"non_missing_pct\"] = 100 - completeness[\"missing_pct\"]\n",
    "\n",
    "# --- 2 Groupwise completeness by Region ---\n",
    "region_completeness = (\n",
    "  df.groupby(\"Region\")\n",
    "    .apply(lambda g: g.isnull().mean() * 100)\n",
    "    .rename_axis(index=None)\n",
    ")\n",
    "\n",
    "# --- 3 Validity checks ---\n",
    "validity = pd.DataFrame()\n",
    "validity[\"width_invalid\"] = (df[\"width\"] <= 0).sum()\n",
    "validity[\"width_null\"] = df[\"width\"].isnull().sum()\n",
    "valid_C_values = df[\"C\"].isin([True, False, 0, 1]).mean() * 100\n",
    "validity[\"C_valid_pct\"] = valid_C_values\n",
    "\n",
    "# --- 4 Consistency check: D should be consistent within Region ---\n",
    "region_D_consistency = (\n",
    "  df.groupby(\"Region\")[\"D\"]\n",
    "    .nunique()\n",
    "    .reset_index(name=\"distinct_D_values\")\n",
    ")\n",
    "region_D_consistency[\"consistent_D\"] = region_D_consistency[\"distinct_D_values\"] == 1\n",
    "\n",
    "# --- 5 Optional: QA scoring per Region ---\n",
    "region_qa = (\n",
    "  df.groupby(\"Region\")\n",
    "    .apply(lambda g: 1 - (g[[\"A\",\"B\",\"width\"]].isnull().sum().sum() / (len(g)*3)))\n",
    "    .reset_index(name=\"qa_score\")\n",
    ")\n",
    "region_qa[\"qa_label\"] = pd.cut(region_qa[\"qa_score\"],\n",
    "                 bins=[0,0.7,0.9,1],\n",
    "                 labels=[\"Poor\",\"Fair\",\"Good\"])\n",
    "\n",
    "# --- 6 Optional: False positive analysis for C ---\n",
    "false_pos_candidates = df[df[\"C\"] == True]\n",
    "\n",
    "# --- Output results using click style ---\n",
    "click.secho(\"=== Overall Completeness ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(completeness)\n",
    "click.secho(\"\\n=== Missing % by Region ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(region_completeness)\n",
    "click.secho(\"\\n=== Validity Checks ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(validity.T)\n",
    "click.secho(\"\\n=== Consistency of D per Region ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(region_D_consistency)\n",
    "click.secho(\"\\n=== QA Score per Region ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(region_qa)\n",
    "click.secho(\"\\n=== Sample suspected false positives in C ===\", fg=\"cyan\", bold=True)\n",
    "click.echo(false_pos_candidates.head(10))\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
